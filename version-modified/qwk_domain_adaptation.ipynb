{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook generates all the QWK scores for set 1 to 8 using the features csv files found in 'features' directory with the include of domain adapation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All implementation are obtained from maes.ipynb\n",
    "\n",
    "Domain adaptation methods used below: \n",
    "- SourceOnly \n",
    "- TargetOnly\n",
    "- EasyAdapt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm #SVR is in SVM\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB, SVM and BLRR model qwk scores generation \n",
    "\n",
    "Put here for referencing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk_nb(x_train, x_test, y_train, y_test):\n",
    "    # Preprocess\n",
    "    x_trainNB = x_train\n",
    "    y_trainNB = y_train\n",
    "    x_testNB = x_test\n",
    "    y_testNB = y_test\n",
    "\n",
    "    # Fit the model\n",
    "    model_nb = naive_bayes.MultinomialNB()\n",
    "    model_nb.fit(x_trainNB, y_trainNB.ravel())\n",
    "    \n",
    "    # Get predicted scores\n",
    "    y_predNB = model_nb.predict(x_testNB)\n",
    "    \n",
    "    # Get QWK score\n",
    "    score = cohen_kappa_score(y_test, y_predNB, weights=\"quadratic\")\n",
    "    return score, y_predNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk_svm(x_train, x_test, y_train, y_test):\n",
    "    # Preprocess\n",
    "    sc_Xsvm = StandardScaler()\n",
    "    sc_ysvm = StandardScaler()\n",
    "    x_trainSVM = sc_Xsvm.fit_transform(x_train)\n",
    "    y_trainSVM = sc_ysvm.fit_transform(y_train)\n",
    "    x_testSVM = sc_Xsvm.transform(x_test)\n",
    "    y_testSVM = sc_ysvm.transform(y_test)\n",
    "    \n",
    "    # Fit the model\n",
    "    from sklearn.svm import SVR\n",
    "    model_svm = SVR(kernel='rbf', gamma='auto', verbose=True)\n",
    "    model_svm.fit(x_trainSVM, y_trainSVM.ravel())\n",
    "    \n",
    "    # Get predicted scores\n",
    "    y_predSVM = model_svm.predict(x_testSVM)\n",
    "    y_predSVM = sc_ysvm.inverse_transform(y_predSVM).round()\n",
    "\n",
    "    # Get QWK score\n",
    "    score = cohen_kappa_score(y_test, y_predSVM, weights=\"quadratic\")\n",
    "    return score, y_predSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk_blrr(x_train, x_test, y_train, y_test):\n",
    "    # Preprocess\n",
    "    sc_Xblrr = StandardScaler()\n",
    "    sc_yblrr = StandardScaler()\n",
    "    x_trainBLRR = sc_Xblrr.fit_transform(x_train)\n",
    "    y_trainBLRR = sc_yblrr.fit_transform(y_train)\n",
    "    x_testBLRR = sc_Xblrr.transform(x_test)\n",
    "    y_testBLRR = sc_yblrr.transform(y_test)\n",
    "    \n",
    "    # Fit the model\n",
    "    from sklearn import linear_model\n",
    "    model_blrr = linear_model.BayesianRidge()\n",
    "    model_blrr.fit(x_trainBLRR, y_trainBLRR.ravel())\n",
    "    \n",
    "    # Get predicted scores\n",
    "    y_predBLRR = model_blrr.predict(x_testBLRR)\n",
    "    y_predBLRR = sc_yblrr.inverse_transform(y_predBLRR).round()\n",
    "\n",
    "    # Get QWK score\n",
    "    score = cohen_kappa_score(y_test, y_predBLRR, weights=\"quadratic\")\n",
    "    return score, y_predBLRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SourceOnly\n",
    "\n",
    "Disclaimer: not too sure of the algorithm used by the SourceOnly to obtain the QWK score, the approach below tries to use all 3 methods to obtain the scores, but have some difference with the Phandi's scores\n",
    "\n",
    "Since target set is not used, so 4-fold cross validation (10, 25, 50, 100) can't be used\n",
    "\n",
    "Probably needs some refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_only(source_set, target_set):\n",
    "    # target_set is omitted as only source is used\n",
    "    source_file = 'features/features_set' + str(source_set) + '.csv'\n",
    "    source_dataset = pd.read_csv(source_file)\n",
    "    \n",
    "    # Reshape data and model (source)\n",
    "    X_train = source_dataset.iloc[:,:15].values.astype(float)\n",
    "    y_train = source_dataset.iloc[:,17].values.astype(float)\n",
    "    y_train = np.array(y_train).reshape(-1,1)\n",
    " \n",
    "    # Getting the QWK scores for all methods\n",
    "    nb_score, _ = qwk_nb(X_train, X_train, y_train, y_train)\n",
    "    svm_score, _ = qwk_svm(X_train, X_train, y_train, y_train)\n",
    "    blrr_score, _ = qwk_blrr(X_train, X_train, y_train, y_train)\n",
    "    \n",
    "    return source_set, target_set, nb_score, svm_score, blrr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for source_no in range(1, 9, 2):\n",
    "    scores.append(source_only(source_no, source_no+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>BLRR</th>\n",
       "      <th>SVM</th>\n",
       "      <th>NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.752705</td>\n",
       "      <td>0.854028</td>\n",
       "      <td>0.810284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.641433</td>\n",
       "      <td>0.724488</td>\n",
       "      <td>0.648126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.743947</td>\n",
       "      <td>0.833932</td>\n",
       "      <td>0.778948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.692859</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>0.705152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target      BLRR       SVM        NB\n",
       "0       1       2  0.752705  0.854028  0.810284\n",
       "1       3       4  0.641433  0.724488  0.648126\n",
       "2       5       6  0.743947  0.833932  0.778948\n",
       "3       7       8  0.692859  0.811989  0.705152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores, columns=['Source', 'Target', 'BLRR', 'SVM', 'NB'])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TargetOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to generate sub samples of 10, 25, 50, 100\n",
    "\"\"\"\n",
    "def sub_sample(data_set, size, selected_set):\n",
    "    net_size = size - len(selected_set)\n",
    "    for i in range(net_size):\n",
    "        found = False\n",
    "        while not found:\n",
    "            index = random.choice(data_set)\n",
    "            if index not in selected_set:\n",
    "                selected_set.append(index)\n",
    "                found = True\n",
    "    return selected_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to obtain the qwk scores of 5 folds for target only based on the given algo (the model to be used)\n",
    "\"\"\"\n",
    "def target_only(source_set, target_set, algo_function):\n",
    "    # source_set is omitted as only target is used\n",
    "    target_file = 'features/features_set' + str(target_set) + '.csv'\n",
    "    target_dataset = pd.read_csv(target_file)\n",
    "    \n",
    "    # Reshape data and model (target)\n",
    "    X = target_dataset.iloc[:,:15].values.astype(float)\n",
    "    y = target_dataset.iloc[:,17].values.astype(float)\n",
    "    y = np.array(y).reshape(-1,1)\n",
    "    \n",
    "    # Apply 5-fold \n",
    "    cv = KFold(n_splits=5)\n",
    "    sizes = [10, 25, 50, 100]\n",
    "    all_scores = []\n",
    "    \n",
    "    # Split into train and test for the 5-fold\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        \n",
    "        # Extract one fold of testing data\n",
    "        X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "        # Sub-sample four folds of training data\n",
    "        sub_sample_index = []\n",
    "        scores = []\n",
    "        for size in sizes:\n",
    "            sub_sample_index = sub_sample(train_index, size, sub_sample_index)\n",
    "            X_train, y_train = X[sub_sample_index], y[sub_sample_index]\n",
    "            \n",
    "            # Getting the QWK scores for the given algo function\n",
    "            score, _ = algo_function(X_train, X_test, y_train, y_test)\n",
    "            scores.append(score)\n",
    "            \n",
    "        all_scores.append(scores)\n",
    "    \n",
    "    # Averaging the qwk scores for the 5 folds\n",
    "    averages = np.array(all_scores).mean(axis=0)\n",
    "    \n",
    "    return source_set, target_set, averages[0], averages[1], averages[2], averages[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TargetOnly for BLRR, SVM and NB methods\n",
    "\n",
    "Not too sure which approach was used in the Phandi's paper hence decided to try all approaches. \n",
    "\n",
    "Can further refine if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "blrr_scores = []\n",
    "svm_scores = []\n",
    "nb_scores = []\n",
    "for source_no in range(1, 9, 2):\n",
    "    blrr_scores.append(target_only(source_no, source_no+1, qwk_blrr))\n",
    "    svm_scores.append(target_only(source_no, source_no+1, qwk_svm))\n",
    "    nb_scores.append(target_only(source_no, source_no+1, qwk_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>n=10</th>\n",
       "      <th>n=25</th>\n",
       "      <th>n=50</th>\n",
       "      <th>n=100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.446515</td>\n",
       "      <td>0.551910</td>\n",
       "      <td>0.581513</td>\n",
       "      <td>0.611588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.535292</td>\n",
       "      <td>0.635263</td>\n",
       "      <td>0.600057</td>\n",
       "      <td>0.633840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.479181</td>\n",
       "      <td>0.577733</td>\n",
       "      <td>0.585821</td>\n",
       "      <td>0.632691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.430290</td>\n",
       "      <td>0.522720</td>\n",
       "      <td>0.562998</td>\n",
       "      <td>0.610911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target      n=10      n=25      n=50     n=100\n",
       "0       1       2  0.446515  0.551910  0.581513  0.611588\n",
       "1       3       4  0.535292  0.635263  0.600057  0.633840\n",
       "2       5       6  0.479181  0.577733  0.585821  0.632691\n",
       "3       7       8  0.430290  0.522720  0.562998  0.610911"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blrr_scores_df = pd.DataFrame(blrr_scores, columns=['Source', 'Target', 'n=10', 'n=25', 'n=50', 'n=100'])\n",
    "blrr_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>n=10</th>\n",
       "      <th>n=25</th>\n",
       "      <th>n=50</th>\n",
       "      <th>n=100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.251940</td>\n",
       "      <td>0.429193</td>\n",
       "      <td>0.474331</td>\n",
       "      <td>0.522236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.345396</td>\n",
       "      <td>0.489750</td>\n",
       "      <td>0.578151</td>\n",
       "      <td>0.600809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.200154</td>\n",
       "      <td>0.352701</td>\n",
       "      <td>0.413846</td>\n",
       "      <td>0.490666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.135212</td>\n",
       "      <td>0.356849</td>\n",
       "      <td>0.486679</td>\n",
       "      <td>0.572888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target      n=10      n=25      n=50     n=100\n",
       "0       1       2  0.251940  0.429193  0.474331  0.522236\n",
       "1       3       4  0.345396  0.489750  0.578151  0.600809\n",
       "2       5       6  0.200154  0.352701  0.413846  0.490666\n",
       "3       7       8  0.135212  0.356849  0.486679  0.572888"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_scores_df = pd.DataFrame(svm_scores, columns=['Source', 'Target', 'n=10', 'n=25', 'n=50', 'n=100'])\n",
    "svm_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>n=10</th>\n",
       "      <th>n=25</th>\n",
       "      <th>n=50</th>\n",
       "      <th>n=100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.368109</td>\n",
       "      <td>0.539057</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.587259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.563427</td>\n",
       "      <td>0.610877</td>\n",
       "      <td>0.655510</td>\n",
       "      <td>0.690880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.429160</td>\n",
       "      <td>0.576719</td>\n",
       "      <td>0.606874</td>\n",
       "      <td>0.629351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.282465</td>\n",
       "      <td>0.320242</td>\n",
       "      <td>0.415089</td>\n",
       "      <td>0.502998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target      n=10      n=25      n=50     n=100\n",
       "0       1       2  0.368109  0.539057  0.541000  0.587259\n",
       "1       3       4  0.563427  0.610877  0.655510  0.690880\n",
       "2       5       6  0.429160  0.576719  0.606874  0.629351\n",
       "3       7       8  0.282465  0.320242  0.415089  0.502998"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_scores_df = pd.DataFrame(nb_scores, columns=['Source', 'Target', 'n=10', 'n=25', 'n=50', 'n=100'])\n",
    "nb_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyAdapt\n",
    "\n",
    "Most source code is obtained from easyadapt_sample.ipynb (located in root folder)\n",
    "\n",
    "Classification model here used is SVM, without the StandardScalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For adding noise to dataset, source code obtain from easyadapt_sample.ipynb located in root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(dataset):\n",
    "    mu = 5\n",
    "    sigma = 0.5      # for EasyAdapt, p is set to 0.5, refer to Phandi's paper\n",
    "    nrow = dataset.shape[0]\n",
    "    ncol = dataset.shape[1]\n",
    "    for column in range(ncol):\n",
    "        c_noise = dataset.iloc[:, column] + np.random.normal(mu, sigma, nrow) \n",
    "        dataset.iloc[:, column] = c_noise\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwk_svm_easyadapt(x_train, x_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Commented out the preprocess of StandardScaler because it yields negative scores, \n",
    "    so decided to use the score given instead\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    # sc_Xsvm = StandardScaler()\n",
    "    # sc_ysvm = StandardScaler()\n",
    "    # x_trainSVM = sc_Xsvm.fit_transform(x_train)\n",
    "    # y_trainSVM = sc_ysvm.fit_transform(y_train)\n",
    "    # x_testSVM = sc_Xsvm.transform(x_test)\n",
    "    # y_testSVM = sc_ysvm.transform(y_test)\n",
    "\n",
    "    # Fit the model\n",
    "    from sklearn.svm import SVR\n",
    "    model_svm = SVR()\n",
    "    model_svm.fit(x_train, y_train.ravel())\n",
    "\n",
    "    # Get predicted scores\n",
    "    y_predSVM = model_svm.predict(x_test)\n",
    "    y_predSVM = y_predSVM.round()\n",
    "\n",
    "    # Get QWK score\n",
    "    score = cohen_kappa_score(y_test, y_predSVM, weights=\"quadratic\")\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training and testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training(X_src_train, X_tgt_train, y_src_train, y_tgt_train):\n",
    "    X1 =  pd.concat([X_src_train.add_prefix('g_'), \n",
    "                     X_src_train.add_prefix('s_')], \n",
    "                     axis = 1)\n",
    "    \n",
    "    X2 =  pd.concat([X_tgt_train.add_prefix('g_'), \n",
    "                     X_tgt_train.add_prefix('t_')], \n",
    "                     axis = 1)\n",
    "    \n",
    "    X_easyadapt_train = pd.concat([X1, X2], axis=0, ignore_index=True).fillna(0)\n",
    "    y_easyadapt_train = pd.concat([y_src_train, y_tgt_train], axis=0, ignore_index=True)\n",
    "    \n",
    "    return X_easyadapt_train, y_easyadapt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_testing(x_easyadapt_train, x_tgt_test, y_tgt_test):\n",
    "    X3 = pd.DataFrame(columns = x_easyadapt_train.columns)\n",
    "    X4 = pd.concat([x_tgt_test.add_prefix('g_'), \n",
    "                    x_tgt_test.add_prefix('t_')], \n",
    "                    axis = 1)\n",
    "    \n",
    "    X_easyadapt_test = pd.concat([X3, X4], axis=0, ignore_index=True).fillna(0)\n",
    "    y_easyadapt_test = y_tgt_test\n",
    "    \n",
    "    return X_easyadapt_test, y_easyadapt_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EasyAdapt 5-fold for sub-sample of 10,25,50,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyadapt(source_set, target_set):\n",
    "    source_file = 'features/features_set' + str(source_set) + '.csv'\n",
    "    source_dataset = pd.read_csv(source_file)\n",
    "\n",
    "    target_file = 'features/features_set' + str(target_set) + '.csv'\n",
    "    target_dataset = pd.read_csv(target_file)\n",
    "    \n",
    "    # add noise to target data\n",
    "    X_tgt = target_dataset.iloc[:,:15]\n",
    "    X_tgt = add_noise(X_tgt)\n",
    "    y_tgt = target_dataset.iloc[:,17]\n",
    "    \n",
    "    # Apply 5-fold \n",
    "    cv = KFold(n_splits=5)\n",
    "    sizes = [10, 25, 50, 100]\n",
    "    all_scores = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(X_tgt):\n",
    "        \n",
    "        # Extract one fold of target-testing data\n",
    "        X_tgt_test, y_tgt_test = X_tgt.iloc[test_index], y_tgt.iloc[test_index]\n",
    "        \n",
    "        # Sub-sample four folds of target-training data\n",
    "        sub_sample_index = []\n",
    "        scores = []\n",
    "        \n",
    "        for size in sizes:\n",
    "            \n",
    "            # Obtain target-training data\n",
    "            sub_sample_index = sub_sample(train_index, size, sub_sample_index)\n",
    "            X_tgt_train, y_tgt_train = X_tgt.iloc[sub_sample_index], y_tgt.iloc[sub_sample_index]\n",
    "            \n",
    "            # Obtain source-training data\n",
    "            X_src_train = source_dataset.iloc[:,:15]\n",
    "            y_src_train = source_dataset.iloc[:,17]\n",
    "            \n",
    "            # Prepare training data by combining source-training and target-training data\n",
    "            X_src_train = source_dataset.iloc[:,:15]\n",
    "            y_src_train = source_dataset.iloc[:,17]\n",
    "            X_easyadapt_train, y_easyadapt_train = prepare_training(X_src_train, X_tgt_train, y_src_train, y_tgt_train)\n",
    "            \n",
    "            # Prepare testing data from target-testing data\n",
    "            X_easyadapt_test, y_easyadapt_test = prepare_testing(X_easyadapt_train, X_tgt_test, y_tgt_test)\n",
    "            \n",
    "            # Reshape data and model\n",
    "            X_easyadapt_train = X_easyadapt_train.values.astype(float)\n",
    "            y_easyadapt_train = y_easyadapt_train.values.astype(float)\n",
    "            y_easyadapt_train = y_easyadapt_train.reshape(-1,1)\n",
    "\n",
    "            X_easyadapt_test = X_easyadapt_test.values.astype(float)\n",
    "            y_easyadapt_test = y_easyadapt_test.values.astype(float)\n",
    "            y_easyadapt_test = y_easyadapt_test.reshape(-1,1)\n",
    "            \n",
    "            # Obtain QWK score\n",
    "            score = qwk_svm_easyadapt(X_easyadapt_train, X_easyadapt_test, y_easyadapt_train, y_easyadapt_test)\n",
    "            scores.append(score)\n",
    "            \n",
    "        all_scores.append(scores)\n",
    "            \n",
    "    # Averaging the qwk scores for the 5 folds\n",
    "    averages = np.array(all_scores).mean(axis=0)\n",
    "    \n",
    "    return source_set, target_set, averages[0], averages[1], averages[2], averages[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "easyadapt_scores = []\n",
    "for source_no in range(1, 9, 2):\n",
    "    easyadapt_scores.append(easyadapt(source_no, source_no+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>n=10</th>\n",
       "      <th>n=25</th>\n",
       "      <th>n=50</th>\n",
       "      <th>n=100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344211</td>\n",
       "      <td>0.438998</td>\n",
       "      <td>0.506372</td>\n",
       "      <td>0.487062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.612535</td>\n",
       "      <td>0.644616</td>\n",
       "      <td>0.628283</td>\n",
       "      <td>0.633504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.593338</td>\n",
       "      <td>0.591510</td>\n",
       "      <td>0.569038</td>\n",
       "      <td>0.603321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.039133</td>\n",
       "      <td>0.214019</td>\n",
       "      <td>0.336371</td>\n",
       "      <td>0.465422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target      n=10      n=25      n=50     n=100\n",
       "0       1       2  0.344211  0.438998  0.506372  0.487062\n",
       "1       3       4  0.612535  0.644616  0.628283  0.633504\n",
       "2       5       6  0.593338  0.591510  0.569038  0.603321\n",
       "3       7       8  0.039133  0.214019  0.336371  0.465422"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easyadapt_scores_df = pd.DataFrame(easyadapt_scores, columns=['Source', 'Target', 'n=10', 'n=25', 'n=50', 'n=100'])\n",
    "easyadapt_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
