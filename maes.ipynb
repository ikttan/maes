{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M - Automated Essay Scoring\n",
    "_School of Information Technology_<br>\n",
    "_Monash University Malaysia_<br>\n",
    "(c) Copyright 2020, Ian Tan & Jun Qing Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps\n",
    "\n",
    "- Read dataset (ASAP)\n",
    "- Extract features (into file) using EASE\n",
    "- Conduct machine learning (Sci-kit Learn libraries)\n",
    "    - Naive Bayes\n",
    "    - SVR\n",
    "    - BLRR (later)\n",
    "- Evaluate (QWK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm #SVR is in SVM\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the EASE functions, which is located in the ease folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'ease')\n",
    "import create\n",
    "import grade \n",
    "import model_creator \n",
    "import predictor_extractor \n",
    "import predictor_set \n",
    "import util_functions\n",
    "import essay_set\n",
    "import feature_extractor\n",
    "\n",
    "from essay_set import EssaySet\n",
    "from feature_extractor import FeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AES (Hewlett Foundation dataset from Kaggle) in the folder `asap-aes`.  For this, we use the `training_set_rel3` for training and the `valid_set` for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"asap-aes/training_set_rel3.tsv\", sep='\\t', encoding=\"latin-1\")\n",
    "test_set = pd.read_csv(\"asap-aes/test_set.tsv\", sep='\\t', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['essay'] = [entry.lower() for entry in train_set['essay']] # lower case for all words in essay\n",
    "test_set['essay'] = [entry.lower() for entry in test_set['essay']] # lower case for all words in essay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 different essay sets.  As an overview:\n",
    "- Sets 1 & 2 are of persuasive/narrative in the form of letters\n",
    "- Sets 3, 4, 5 & 6 are source dependent response to a given essay\n",
    "- Sets 7 & 8 are of persuasive/narrative in the form of story writing essays\n",
    "\n",
    "These format makes it good for transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_1 = train_set[train_set['essay_set'] == 1]\n",
    "train_set_2 = train_set[train_set['essay_set'] == 2]\n",
    "#train_set_3 = train_set[train_set['essay_set'] == 3]\n",
    "#train_set_4 = train_set[train_set['essay_set'] == 4]\n",
    "#train_set_5 = train_set[train_set['essay_set'] == 5]\n",
    "#train_set_6 = train_set[train_set['essay_set'] == 6]\n",
    "train_set_7 = train_set[train_set['essay_set'] == 7]\n",
    "train_set_8 = train_set[train_set['essay_set'] == 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do similarly for the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_1 = test_set[test_set['essay_set'] == 1]\n",
    "test_set_2 = test_set[test_set['essay_set'] == 2]\n",
    "#test_set_3 = test_set[test_set['essay_set'] == 3]\n",
    "#test_set_4 = test_set[test_set['essay_set'] == 4]\n",
    "#test_set_5 = test_set[test_set['essay_set'] == 5]\n",
    "#test_set_6 = test_set[test_set['essay_set'] == 6]\n",
    "test_set_7 = test_set[test_set['essay_set'] == 7]\n",
    "test_set_8 = test_set[test_set['essay_set'] == 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each set will retain the original index, we want each of them to have their own indexing so that it is easier to match the essay and the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_1 = train_set_1.reset_index() # resets index\n",
    "train_set_2 = train_set_2.reset_index()\n",
    "#train_set_3 = train_set_3.reset_index()\n",
    "#train_set_4 = train_set_4.reset_index()\n",
    "#train_set_5 = train_set_5.reset_index()\n",
    "#train_set_6 = train_set_6.reset_index()\n",
    "train_set_7 = train_set_7.reset_index()\n",
    "train_set_8 = train_set_8.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_1 = test_set_1.reset_index() # resets index\n",
    "test_set_2 = test_set_2.reset_index()\n",
    "#test_set_3 = test_set_3.reset_index()\n",
    "#test_set_4 = test_set_4.reset_index()\n",
    "#test_set_5 = test_set_5.reset_index()\n",
    "#test_set_6 = test_set_6.reset_index()\n",
    "test_set_7 = test_set_7.reset_index()\n",
    "test_set_8 = test_set_8.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use just the `essay` content and the respective `scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want for the whole dataset.\n",
    "# Commented out as we will work on individual datasets\n",
    "#essays = train_set['essay']\n",
    "#scores = train_set['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_1 = train_set_1['essay']\n",
    "scores_1 = train_set_1['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_2 = train_set_2['essay']\n",
    "scores_2 = train_set_2['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#essays_3 = train_set_3['essay']\n",
    "#scores_3 = train_set_3['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#essays_4 = train_set_4['essay']\n",
    "#scores_4 = train_set_4['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#essays_5 = train_set_5['essay']\n",
    "#scores_5 = train_set_5['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#essays_6 = train_set_6['essay']\n",
    "#scores_6 = train_set_6['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_7 = train_set_7['essay']\n",
    "scores_7 = train_set_7['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_8 = train_set_8['essay']\n",
    "scores_8 = train_set_8['domain1_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the `domain1_score` column to `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1.columns = \"score\"\n",
    "scores_2.columns = \"score\"\n",
    "#scores_3.columns = \"score\"\n",
    "#scores_4.columns = \"score\"\n",
    "#scores_5.columns = \"score\"\n",
    "#scores_6.columns = \"score\"\n",
    "scores_7.columns = \"score\"\n",
    "scores_8.columns = \"score\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE ABOVE NEEDS TO BE PUT INTO A LOOP BUT I LEFT IT AS IS BECAUSE YOU CAN PICK AND CHOOSE EASILY INSTEAD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the essay sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, these can be looped but I kept them separated for ease of readability and commenting out those that we don't need.  Each set takes a long time to process, and hence please be patient with this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_set_1 = EssaySet()\n",
    "e_set_2 = EssaySet()\n",
    "#e_set_3 = EssaySet()\n",
    "#e_set_4 = EssaySet()\n",
    "#e_set_5 = EssaySet()\n",
    "#e_set_6 = EssaySet()\n",
    "e_set_7 = EssaySet()\n",
    "e_set_8 = EssaySet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(essays_1)):\n",
    "    e_set_1.add_essay(essays_1[i], scores_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(essays_2)):\n",
    "    e_set_2.add_essay(essays_2[i], scores_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left out for sets 3 - 6 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(essays_7)):\n",
    "    e_set_7.add_essay(essays_7[i], scores_7[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(essays_8)):\n",
    "    e_set_8.add_essay(essays_8[i], scores_8[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently only doing for Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_extractor = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = f_extractor.gen_length_feats(e_set_1)\n",
    "length_df_1 = pd.DataFrame(\n",
    "    length, \n",
    "    columns = [\n",
    "        'chars', \n",
    "        'words', \n",
    "        'commas', \n",
    "        'apostrophes', \n",
    "        'punctuations', \n",
    "        'avg_word_length',\n",
    "        # new stuff\n",
    "        'paragraphs',\n",
    "        #'avg_word_sentence',\n",
    "        #'avg_sentence_para',\n",
    "        'POS', \n",
    "        'POS/total_words'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1908.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.904884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>385.324675</td>\n",
       "      <td>0.990552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2309.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.030501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>454.991209</td>\n",
       "      <td>0.991266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1560.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.993464</td>\n",
       "      <td>0.990301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3130.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.452962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>569.992982</td>\n",
       "      <td>0.993019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2615.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.028846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.634367</td>\n",
       "      <td>0.980066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0  1908.0  389.0    18.0          7.0          16.0         4.904884   \n",
       "1  2309.0  459.0    12.0          5.0          20.0         5.030501   \n",
       "2  1560.0  310.0     9.0          6.0          14.0         5.032258   \n",
       "3  3130.0  574.0    13.0          7.0          27.0         5.452962   \n",
       "4  2615.0  520.0    13.0          7.0          30.0         5.028846   \n",
       "\n",
       "   paragraphs         POS  POS/total_words  \n",
       "0         0.0  385.324675         0.990552  \n",
       "1         0.0  454.991209         0.991266  \n",
       "2         0.0  306.993464         0.990301  \n",
       "3         0.0  569.992982         0.993019  \n",
       "4         0.0  509.634367         0.980066  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>2614.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.831793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>533.988785</td>\n",
       "      <td>0.987040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1130.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.747899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.991453</td>\n",
       "      <td>0.987359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1671.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>314.993631</td>\n",
       "      <td>0.990546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>78.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>1139.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.826271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.318966</td>\n",
       "      <td>0.984402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "1778  2614.0  541.0     7.0         13.0          22.0         4.831793   \n",
       "1779  1130.0  238.0     3.0         14.0          19.0         4.747899   \n",
       "1780  1671.0  318.0     0.0          7.0          18.0         5.254717   \n",
       "1781    78.0   18.0     1.0          2.0           0.0         4.333333   \n",
       "1782  1139.0  236.0     0.0          2.0          18.0         4.826271   \n",
       "\n",
       "      paragraphs         POS  POS/total_words  \n",
       "1778         0.0  533.988785         0.987040  \n",
       "1779         0.0  234.991453         0.987359  \n",
       "1780         0.0  314.993631         0.990546  \n",
       "1781         0.0   17.000000         0.944444  \n",
       "1782         0.0  232.318966         0.984402  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_df_1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_*Exclude the prompts for the time being*_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge this with the score based on the index\n",
    "# We use the shallow features first\n",
    "features = length_df_1\n",
    "dataset = features.merge(scores_1, left_index=True, right_index=True)\n",
    "dataset.columns = ['chars', 'words', 'commas', 'apostrophes', 'punctuations',\n",
    "       'avg_word_length', 'POS', 'POS/total_words', 'score']\n",
    "X_1 = dataset.iloc[:,0:7].values.astype(float)\n",
    "y_1 = dataset.iloc[:,8].values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = np.array(y_1).reshape(-1,1)\n",
    "y_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb_1 = naive_bayes.MultinomialNB()\n",
    "model_nb_1.fit(X_1, y_1.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the Naive Bayes model is called `model_nb_1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use standard scaler for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_1 = sc_X.fit_transform(X_1)\n",
    "y_1 = sc_y.fit_transform(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "# most important SVR parameter is Kernel type. It can be #linear,polynomial or gaussian SVR. We have a non-linear condition #so we can select polynomial or gaussian but here we select RBF(a #gaussian type) kernel.\n",
    "# kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
    "# maybe use poly and increase the degree\n",
    "regressor = SVR(kernel='rbf', gamma='auto', verbose=True)\n",
    "#regressor = SVR(kernel='poly', degree=5, gamma='auto', verbose=True)\n",
    "regressor.fit(X_1,y_1.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLRR (Later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the respective validation set and will have to also pre-process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLRR (Later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using QWK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QWK scores for NB, SVR and BLRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collate the essay prompts\n",
    "This consist of one essay from each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_prompts = []\n",
    "\n",
    "# Takes a bit of time also :)\n",
    "for i in range(1,9):\n",
    "    file = \"prompts/set\" + str(i) + \".txt\"\n",
    "    f = open(file, \"r\", encoding=\"latin-1\") # there are some 0x9x characters, hence need to specify encoding\n",
    "    essay_prompts.append(f.read())\n",
    "    \n",
    "def get_essay_prompt(essay_set):\n",
    "    return essay_prompts[essay_set-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsure how this works\n",
    "e_set.update_prompt(get_essay_prompt(2))\n",
    "\n",
    "# Need more explanation on how this works - look into EASE\n",
    "\n",
    "prompts = f_extractor.gen_prompt_feats(e_set)\n",
    "prompts_df = pd.DataFrame(prompts, columns = ['prompt_words', 'prompt_words/total_words', 'synonym_words', 'synonym_words/total_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another process that takes sometime to process\n",
    "unstemmed = util_functions.get_vocab_essays_count(e_set._text, e_set._score)\n",
    "stemmed = util_functions.get_vocab_essays_count(e_set._clean_stem_text, e_set._score)\n",
    "\n",
    "bow = list(map(lambda a,b:[a,b], unstemmed, stemmed))\n",
    "bow_df = pd.DataFrame(bow, columns = ['unstemmed', 'stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([length_df, prompts_df, bow_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export features to a file for next stage (optional)\n",
    "dataset = features.merge(scores, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = ['chars', 'words', 'commas', 'apostrophes', 'punctuations',\n",
    "       'avg_word_length', 'POS', 'POS/total_words', 'prompt_words',\n",
    "       'prompt_words/total_words', 'synonym_words',\n",
    "       'synonym_words/total_words', 'unstemmed', 'stemmed', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('maes_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can just use the features and score for the X and y but just to keep to certain convention if reading back from the CSV file above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:13].values.astype(float)\n",
    "y = dataset.iloc[:,14].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y).reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conduct Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "y = sc_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split the train / test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Have a look at the first few lines\n",
    "print(y_test[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "# most important SVR parameter is Kernel type. It can be #linear,polynomial or gaussian SVR. We have a non-linear condition #so we can select polynomial or gaussian but here we select RBF(a #gaussian type) kernel.\n",
    "# kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
    "# maybe use poly and increase the degree\n",
    "regressor = SVR(kernel='rbf', gamma='auto', verbose=True)\n",
    "#regressor = SVR(kernel='poly', degree=5, gamma='auto', verbose=True)\n",
    "regressor.fit(X_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test / Predict the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used yet as I don't have a sample X\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred = sc_y.inverse_transform(y_pred).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'Real Values':sc_y.inverse_transform(y_test.reshape(-1)),\n",
    "        'Predicted Values':y_pred\n",
    "    }\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = sc_y.inverse_transform(y_test).round()\n",
    "# y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to wrap my head around this (where's the predictor)\n",
    "\n",
    "print(\"accuracy score:\", regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy score:\", accuracy_score(df['Real Values'], df['Predicted Values']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cohen_kappa_score(sc_y.inverse_transform(y_test).round(), y_pred, weights=\"quadratic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test = sc_X.inverse_transform(X_train)\n",
    "X_train_test = X_train_test.astype(int)\n",
    "X_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_test = sc_y.inverse_transform(y_train.reshape(-1))\n",
    "y_train_test = y_train_test.astype(int)\n",
    "y_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbclassifier = naive_bayes.MultinomialNB()\n",
    "nbclassifier.fit(X_train_test, y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_test = sc_X.inverse_transform(X_test)\n",
    "X_test_test = X_test_test.astype(int)\n",
    "X_test_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_test = sc_y.inverse_transform(y_test.reshape(-1))\n",
    "y_test_test = y_test_test.astype(int)\n",
    "y_test_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predNB = nbclassifier.predict(X_test_test)\n",
    "\n",
    "cm = confusion_matrix(y_test_test, y_predNB)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rpt = classification_report(y_test_test, y_predNB)\n",
    "print(rpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QWK Scores (Manual Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(cm) # Just to get the same size as the confusion matrix from above\n",
    "w = np.zeros((N,N)) # create a matrix of N by N\n",
    "d = (N-1)**2 # the weighted portion\n",
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        w[i][j] = float(((i-j)**2)/d) \n",
    "w # The weighted matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_predNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_hist=np.zeros([N])\n",
    "for item in y_test_test: \n",
    "    act_hist[item-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hist=np.zeros([N])\n",
    "for item in y_predNB: \n",
    "    pred_hist[item-1]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.outer(act_hist, pred_hist)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = E/E.sum()\n",
    "E.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = cm/cm.sum()\n",
    "cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=0\n",
    "den=0\n",
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        num+=w[i][j]*cm[i][j]\n",
    "        den+=w[i][j]*E[i][j]\n",
    "            \n",
    "weighted_kappa = (1 - (num/den))\n",
    "weighted_kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QWK scores output are from -1 to 1, where -1 means that it is totally wrong while 1 is a perfect match (classification).  The aim is to get as close as possible to 1, with a score of 0.6 being generally accepted as a good score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QWK for Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is a manual computation of the QWK, which we later found that it is already available as an option with the [Cohen Kappa Score](https://journals.sagepub.com/doi/10.1177/001316446002000104) in sklearn, when we set the weights to 'quadratic'.  Since it has already been manually coded above, we use the sklearn.metrics.cohen_kappa_score to validate our manual coded scoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cohen_kappa_score(y_test_test, y_predNB))\n",
    "print(cohen_kappa_score(y_test_test, y_predNB, weights=\"quadratic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the output of the QWK agreements, the score is just \"moderate agreement\".  Work now is to achieve substantial agreement.\n",
    "\n",
    "https://www.statisticshowto.com/cohens-kappa-statistic/\n",
    "\n",
    "In short, SVM works a little better than Naive Bayes for AES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
