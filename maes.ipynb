{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M - Automated Essay Scoring\n",
    "_School of Information Technology_<br>\n",
    "_Monash University Malaysia_<br>\n",
    "(c) Copyright 2020, Ian Tan & Jun Qing Lim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps\n",
    "\n",
    "- Read dataset (ASAP)\n",
    "- Extract features (into file) using EASE\n",
    "- Conduct machine learning (Sci-kit Learn libraries)\n",
    "    - Naive Bayes\n",
    "    - SVR\n",
    "    - BLRR (later)\n",
    "- Evaluate (QWK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm #SVR is in SVM\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the EASE functions, which is located in the ease folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'ease')\n",
    "import create\n",
    "import grade \n",
    "import model_creator \n",
    "import predictor_extractor \n",
    "import predictor_set \n",
    "import util_functions\n",
    "import essay_set\n",
    "import feature_extractor\n",
    "\n",
    "from essay_set import EssaySet\n",
    "from feature_extractor import FeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AES (Hewlett Foundation dataset from Kaggle) in the folder `asap-aes`.  For this, we use the `training_set_rel3` for training and testing.  Note that the `test_set` and the `valid_set` cannot be used as they don't contain the scores and are meant for the competition to score the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"asap-aes/training_set_rel3.tsv\", sep='\\t', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set['essay'] = [entry.lower() for entry in data_set['essay']] # lower case for all words in essay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 different essay sets.  As an overview:\n",
    "- Sets 1 & 2 are of persuasive/narrative in the form of letters\n",
    "- Sets 3, 4, 5 & 6 are source dependent response to a given essay\n",
    "- Sets 7 & 8 are of persuasive/narrative in the form of story writing essays\n",
    "\n",
    "These format makes it good for transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_1 = data_set[data_set['essay_set'] == 1]\n",
    "data_set_2 = data_set[data_set['essay_set'] == 2]\n",
    "#data_set_3 = data_set[data_set['essay_set'] == 3]\n",
    "#data_set_4 = data_set[data_set['essay_set'] == 4]\n",
    "#data_set_5 = data_set[data_set['essay_set'] == 5]\n",
    "#data_set_6 = data_set[data_set['essay_set'] == 6]\n",
    "#data_set_7 = data_set[data_set['essay_set'] == 7]\n",
    "#data_set_8 = data_set[data_set['essay_set'] == 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each set will retain the original index, we want each of them to have their own indexing so that it is easier to match the essay and the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_1 = data_set_1.reset_index() # resets index\n",
    "data_set_2 = data_set_2.reset_index()\n",
    "#data_set_3 = data_set_3.reset_index()\n",
    "#data_set_4 = data_set_4.reset_index()\n",
    "#data_set_5 = data_set_5.reset_index()\n",
    "#data_set_6 = data_set_6.reset_index()\n",
    "#data_set_7 = data_set_7.reset_index()\n",
    "#data_set_8 = data_set_8.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use just the `essay` content and the respective `scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want for the whole dataset.\n",
    "# Commented out as we will work on individual datasets\n",
    "#essays = data_set['essay']\n",
    "#scores = data_set['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_1 = data_set_1['essay']\n",
    "scores_1 = data_set_1['domain1_score']\n",
    "essays_2 = data_set_2['essay']\n",
    "scores_2 = data_set_2['domain1_score']\n",
    "#essays_3 = data_set_3['essay']\n",
    "#scores_3 = data_set_3['domain1_score']\n",
    "#essays_4 = data_set_4['essay']\n",
    "#scores_4 = data_set_4['domain1_score']\n",
    "#essays_5 = data_set_5['essay']\n",
    "#scores_5 = data_set_5['domain1_score']\n",
    "#essays_6 = data_set_6['essay']\n",
    "#scores_6 = data_set_6['domain1_score']\n",
    "#essays_7 = data_set_7['essay']\n",
    "#scores_7 = data_set_7['domain1_score']\n",
    "#essays_8 = data_set_8['essay']\n",
    "#scores_8 = data_set_8['domain1_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the `domain1_score` column to `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1.columns = \"score\"\n",
    "scores_2.columns = \"score\"\n",
    "#scores_3.columns = \"score\"\n",
    "#scores_4.columns = \"score\"\n",
    "#scores_5.columns = \"score\"\n",
    "#scores_6.columns = \"score\"\n",
    "#scores_7.columns = \"score\"\n",
    "#scores_8.columns = \"score\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE ABOVE NEEDS TO BE PUT INTO A LOOP BUT I LEFT IT AS IS BECAUSE YOU CAN PICK AND CHOOSE EASILY INSTEAD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the essay sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, these can be looped but I kept them separated for ease of readability and commenting out those that we don't need.  Each set takes a long time to process, and hence please be patient with this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_set_1 = EssaySet()\n",
    "e_set_2 = EssaySet()\n",
    "#e_set_3 = EssaySet()\n",
    "#e_set_4 = EssaySet()\n",
    "#e_set_5 = EssaySet()\n",
    "#e_set_6 = EssaySet()\n",
    "#e_set_7 = EssaySet()\n",
    "#e_set_8 = EssaySet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(essays_1)):\n",
    "    e_set_1.add_essay(essays_1[i], scores_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(essays_2)):\n",
    "    e_set_2.add_essay(essays_2[i], scores_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left out for sets 3 - 6 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(essays_7)):\\n    e_set_7.add_essay(essays_7[i], scores_7[i])\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(len(essays_7)):\n",
    "    e_set_7.add_essay(essays_7[i], scores_7[i])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(essays_8)):\\n    e_set_8.add_essay(essays_8[i], scores_8[i])\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(len(essays_8)):\n",
    "    e_set_8.add_essay(essays_8[i], scores_8[i])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_extractor = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the next two variable assignment to change the evaluation of the essay sets.\n",
    "\n",
    "Would be better to do this above.\n",
    "\n",
    "**SETUP HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_set = e_set_2\n",
    "score = scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = f_extractor.gen_length_feats(e_set)\n",
    "length_df = pd.DataFrame(\n",
    "    length, \n",
    "    columns = [\n",
    "        'chars', \n",
    "        'words', \n",
    "        'commas', \n",
    "        'apostrophes', \n",
    "        'punctuations', \n",
    "        'avg_word_length',\n",
    "        # new stuff, will need to compare original with new and separate punctuations\n",
    "        'sentences',\n",
    "        'questions',\n",
    "        'avg_word_sentence',\n",
    "        'punctuations_new',\n",
    "        'POS', \n",
    "        'POS/total_words'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_*Exclude the prompts for the time being*_\n",
    "\n",
    "To be included next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge this with the score based on the index\n",
    "# We use the shallow features first\n",
    "features = length_df\n",
    "dataset = features.merge(score, left_index=True, right_index=True)\n",
    "dataset.columns = ['chars', 'words', 'commas', 'apostrophes', 'punctuations',\n",
    "                   'avg_word_length', 'sentences', 'questions', 'avg_word_sentence', 'punctuations_new',\n",
    "                   'POS', 'POS/total_words', 'score']\n",
    "#X_1 = dataset.iloc[:,0:10].values.astype(float)\n",
    "#y_1 = dataset.iloc[:,11].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset-ori = dataset[['chars', 'words', 'commas', 'apostrophes', 'punctuations', 'avg_word_length',\n",
    "                      'POS', 'POS/total_words', 'score']]\n",
    "dataset-new = dataset[['chars', 'words', 'commas', 'apostrophes', 'avg_word_length',\n",
    "                      'sentences', 'questions', 'avg_word_sentence', 'punctuations_new',\n",
    "                      'POS', 'POS/total_words', 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Essay Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_prompts = []\n",
    "\n",
    "for i in range(1,9):\n",
    "    file = \"prompts/set\" + str(i) + \".txt\"\n",
    "    f = open(file, \"r\", encoding=\"latin-1\") # there are some 0x9x characters, hence need to specify encoding\n",
    "    essay_prompts.append(f.read())\n",
    "    \n",
    "def get_essay_prompt(essay_set):\n",
    "    return essay_prompts[essay_set-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(essay_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SETUP HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<essay_set.EssaySet at 0x1f9dde55240>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unsure how this works\n",
    "e_set.update_prompt(get_essay_prompt(2))\n",
    "\n",
    "# Need more explanation on how this works - look into EASE\n",
    "prompts = f_extractor.gen_prompt_feats(e_set)\n",
    "prompts_df = pd.DataFrame(prompts, columns = [\n",
    "    'prompt_words', 'prompt_words/total_words', 'synonym_words', 'synonym_words/total_words'\n",
    "])\n",
    "e_set # To check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another process that takes sometime to process\n",
    "unstemmed = util_functions.get_vocab_essays_count(e_set._text, e_set._score)\n",
    "stemmed = util_functions.get_vocab_essays_count(e_set._clean_stem_text, e_set._score)\n",
    "\n",
    "bow = list(map(lambda a,b:[a,b], unstemmed, stemmed))\n",
    "bow_df = pd.DataFrame(bow, columns = ['unstemmed', 'stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2639.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.007590</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.095238</td>\n",
       "      <td>32.791587</td>\n",
       "      <td>0.062223</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.417457</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.212524</td>\n",
       "      <td>584</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.672222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.866290</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1181.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.524904</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>22.171206</td>\n",
       "      <td>0.084947</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>291</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2705.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.132827</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.026769</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.464896</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.248577</td>\n",
       "      <td>547</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2394.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.778443</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.181818</td>\n",
       "      <td>31.795655</td>\n",
       "      <td>0.063464</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.431138</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.233533</td>\n",
       "      <td>591</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0  2639.0  527.0    15.0         13.0           0.0         5.007590   \n",
       "1   841.0  180.0     5.0          2.0           0.0         4.672222   \n",
       "2  1181.0  261.0    12.0         15.0           0.0         4.524904   \n",
       "3  2705.0  527.0    22.0          6.0           0.0         5.132827   \n",
       "4  2394.0  501.0    25.0         15.0           2.0         4.778443   \n",
       "\n",
       "   sentences  questions  avg_word_sentence        POS  POS/total_words  \\\n",
       "0       21.0        0.0          25.095238  32.791587         0.062223   \n",
       "1        3.0        0.0          60.000000  17.866290         0.099257   \n",
       "2       10.0        4.0          26.100000  22.171206         0.084947   \n",
       "3       31.0        0.0          17.000000   7.026769         0.013334   \n",
       "4       33.0        1.0          15.181818  31.795655         0.063464   \n",
       "\n",
       "   prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0         220.0                  0.417457          112.0   \n",
       "1          82.0                  0.455556           66.0   \n",
       "2         144.0                  0.551724           83.0   \n",
       "3         245.0                  0.464896          131.0   \n",
       "4         216.0                  0.431138          117.0   \n",
       "\n",
       "   synonym_words/total_words  unstemmed  stemmed  \n",
       "0                   0.212524        584      559  \n",
       "1                   0.366667        210      210  \n",
       "2                   0.318008        291      285  \n",
       "3                   0.248577        547      528  \n",
       "4                   0.233533        591      562  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.concat([length_df, prompts_df, bow_df], axis=1, sort=False)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>commas</th>\n",
       "      <th>apostrophes</th>\n",
       "      <th>punctuations</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>sentences</th>\n",
       "      <th>questions</th>\n",
       "      <th>avg_word_sentence</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS/total_words</th>\n",
       "      <th>prompt_words</th>\n",
       "      <th>prompt_words/total_words</th>\n",
       "      <th>synonym_words</th>\n",
       "      <th>synonym_words/total_words</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2639.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.007590</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.095238</td>\n",
       "      <td>32.791587</td>\n",
       "      <td>0.062223</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.417457</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.212524</td>\n",
       "      <td>584</td>\n",
       "      <td>559</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.672222</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.866290</td>\n",
       "      <td>0.099257</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1181.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.524904</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>22.171206</td>\n",
       "      <td>0.084947</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>291</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2705.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.132827</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.026769</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.464896</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.248577</td>\n",
       "      <td>547</td>\n",
       "      <td>528</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2394.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.778443</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.181818</td>\n",
       "      <td>31.795655</td>\n",
       "      <td>0.063464</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.431138</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.233533</td>\n",
       "      <td>591</td>\n",
       "      <td>562</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chars  words  commas  apostrophes  punctuations  avg_word_length  \\\n",
       "0  2639.0  527.0    15.0         13.0           0.0         5.007590   \n",
       "1   841.0  180.0     5.0          2.0           0.0         4.672222   \n",
       "2  1181.0  261.0    12.0         15.0           0.0         4.524904   \n",
       "3  2705.0  527.0    22.0          6.0           0.0         5.132827   \n",
       "4  2394.0  501.0    25.0         15.0           2.0         4.778443   \n",
       "\n",
       "   sentences  questions  avg_word_sentence        POS  POS/total_words  \\\n",
       "0       21.0        0.0          25.095238  32.791587         0.062223   \n",
       "1        3.0        0.0          60.000000  17.866290         0.099257   \n",
       "2       10.0        4.0          26.100000  22.171206         0.084947   \n",
       "3       31.0        0.0          17.000000   7.026769         0.013334   \n",
       "4       33.0        1.0          15.181818  31.795655         0.063464   \n",
       "\n",
       "   prompt_words  prompt_words/total_words  synonym_words  \\\n",
       "0         220.0                  0.417457          112.0   \n",
       "1          82.0                  0.455556           66.0   \n",
       "2         144.0                  0.551724           83.0   \n",
       "3         245.0                  0.464896          131.0   \n",
       "4         216.0                  0.431138          117.0   \n",
       "\n",
       "   synonym_words/total_words  unstemmed  stemmed  domain1_score  \n",
       "0                   0.212524        584      559              4  \n",
       "1                   0.366667        210      210              1  \n",
       "2                   0.318008        291      285              2  \n",
       "3                   0.248577        547      528              4  \n",
       "4                   0.233533        591      562              4  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export features to a file for next stage (optional)\n",
    "dataset = features.merge(score, left_index=True, right_index=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dataset.columns = ['chars', 'words', 'commas', 'apostrophes', 'punctuations',\n",
    "                   'avg_word_length', 'sentences', 'questions', 'avg_word_sentence',\n",
    "                   'POS', 'POS/total_words',\n",
    "                   'score']\n",
    "\"\"\"\n",
    "\n",
    "dataset.columns = ['chars', 'words', 'commas', 'apostrophes', 'punctuations',\n",
    "                   'avg_word_length', 'sentences', 'questions', 'avg_word_sentence',\n",
    "                   'POS', 'POS/total_words',\n",
    "                   'prompt_words', 'prompt_words/total_words', 'synonym_words',\n",
    "                   'synonym_words/total_words', 'unstemmed', 'stemmed',\n",
    "                   'score']\n",
    "dataset.head()\n",
    "dataset.to_csv('maes_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can just use the features and score for the X and y but just to keep to certain convention if reading back from the CSV file above.\n",
    "\n",
    "**YOU CAN RUN FROM HERE ON BY READING THE FEATURES FOR THE TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('maes_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 1., 2., ..., 2., 3., 3.])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[:,1:16].values.astype(float)\n",
    "y = dataset.iloc[:,18].values.astype(float)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 15)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 1)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y).reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.]\n",
      " [5.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]]\n"
     ]
    }
   ],
   "source": [
    "### Split the train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# Have a look at the first few lines\n",
    "print(y_test[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No scaling used for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainNB = X_train\n",
    "y_trainNB = y_train\n",
    "X_testNB = X_test\n",
    "y_testNB = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = naive_bayes.MultinomialNB()\n",
    "model_nb.fit(X_trainNB, y_trainNB.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the Naive Bayes model is called `model_nb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use standard scaler for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_Xsvm = StandardScaler()\n",
    "sc_ysvm = StandardScaler()\n",
    "X_trainSVM = sc_Xsvm.fit_transform(X_train)\n",
    "y_trainSVM = sc_ysvm.fit_transform(y_train)\n",
    "X_testSVM = sc_Xsvm.transform(X_test)\n",
    "y_testSVM = sc_ysvm.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "# most important SVR parameter is Kernel type. It can be #linear,polynomial or gaussian SVR. We have a non-linear condition #so we can select polynomial or gaussian but here we select RBF(a #gaussian type) kernel.\n",
    "# kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
    "# maybe use poly and increase the degree\n",
    "model_svm = SVR(kernel='rbf', gamma='auto', verbose=True)\n",
    "#regressor = SVR(kernel='poly', degree=5, gamma='auto', verbose=True)\n",
    "model_svm.fit(X_trainSVM,y_trainSVM.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the Support Vector Machine (SVM) model is called `model_svm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_Xblrr = StandardScaler()\n",
    "sc_yblrr = StandardScaler()\n",
    "X_trainBLRR = sc_Xblrr.fit_transform(X_train)\n",
    "y_trainBLRR = sc_yblrr.fit_transform(y_train)\n",
    "X_testBLRR = sc_Xblrr.transform(X_test)\n",
    "y_testBLRR = sc_yblrr.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
       "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "       normalize=False, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "model_blrr = linear_model.BayesianRidge()\n",
    "model_blrr.fit(X_trainBLRR, y_trainBLRR.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, the Bayesian Linear Ridge Regression (BLRR) model is called `model_blrr_1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the respective validation set and will have to also pre-process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   4   1   0   0   0]\n",
      " [  1  12   9   1   0   0]\n",
      " [  1  10 108  40   0   1]\n",
      " [  0   1  45  94  13   3]\n",
      " [  0   0   0   3   9   1]\n",
      " [  0   0   0   0   1   0]]\n"
     ]
    }
   ],
   "source": [
    "y_predNB = model_nb.predict(X_testNB)\n",
    "#y_1_predNB = sc_ynb.inverse_transform(y_1_predNB).round()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predNB)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 6., 3., 3., 5., 3., 3., 4., 4., 3., 5., 4., 4., 3., 3., 5., 3.,\n",
       "       3., 3., 3., 5., 4., 4., 3., 3., 3., 3., 3., 4., 4., 4., 4., 3., 5.,\n",
       "       2., 4., 6., 2., 2., 4., 3., 3., 4., 2., 3., 3., 3., 2., 4., 3., 3.,\n",
       "       4., 4., 3., 4., 2., 3., 3., 3., 4., 3., 5., 3., 2., 4., 3., 4., 3.,\n",
       "       5., 3., 3., 3., 3., 4., 3., 3., 4., 6., 4., 3., 4., 2., 4., 4., 4.,\n",
       "       3., 3., 4., 3., 5., 4., 4., 3., 4., 3., 4., 3., 1., 3., 3., 4., 4.,\n",
       "       4., 3., 4., 3., 4., 2., 3., 2., 4., 3., 5., 3., 3., 4., 4., 3., 4.,\n",
       "       4., 3., 3., 3., 5., 2., 1., 3., 1., 5., 3., 3., 3., 4., 4., 3., 3.,\n",
       "       4., 4., 3., 6., 3., 3., 3., 5., 3., 3., 4., 6., 4., 3., 4., 4., 4.,\n",
       "       4., 3., 4., 3., 5., 4., 3., 3., 3., 3., 3., 3., 4., 3., 4., 3., 4.,\n",
       "       5., 3., 3., 4., 4., 3., 4., 4., 2., 2., 3., 5., 2., 4., 3., 3., 4.,\n",
       "       3., 4., 3., 4., 1., 4., 3., 4., 4., 3., 4., 3., 4., 4., 4., 4., 3.,\n",
       "       4., 4., 3., 3., 2., 4., 3., 4., 3., 2., 3., 4., 3., 3., 4., 4., 5.,\n",
       "       4., 5., 3., 4., 4., 3., 3., 3., 2., 3., 3., 3., 3., 3., 3., 3., 4.,\n",
       "       5., 4., 3., 3., 3., 4., 3., 3., 2., 4., 4., 3., 4., 3., 4., 3., 3.,\n",
       "       4., 3., 2., 3., 3., 4., 4., 4., 3., 4., 4., 3., 4., 4., 4., 4., 4.,\n",
       "       3., 3., 4., 4., 2., 3., 4., 5., 3., 4., 4., 4., 3., 3., 3., 3., 4.,\n",
       "       4., 5., 4., 4., 2., 4., 3., 4., 3., 4., 4., 5., 4., 4., 4., 3., 4.,\n",
       "       3., 4., 4., 3., 4., 4., 4., 4., 3., 4., 3., 3., 5., 3., 3., 3., 3.,\n",
       "       3., 3., 4., 3., 3., 2., 5., 3., 3., 3., 4., 4., 3., 3., 2., 2., 4.,\n",
       "       3., 4., 4., 2., 3., 2., 3., 3., 2., 3., 3., 4., 4., 3., 3., 4., 3.,\n",
       "       3., 4., 4.])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   6   1   0   0   0]\n",
      " [  0  11  11   1   0   0]\n",
      " [  0   1 117  42   0   0]\n",
      " [  0   0  45 111   0   0]\n",
      " [  0   0   0  13   0   0]\n",
      " [  0   0   0   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "y_predSVM = model_svm.predict(X_testSVM)\n",
    "y_predSVM = sc_ysvm.inverse_transform(y_predSVM).round()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predSVM)\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4., 3., 3., 4., 3., 4., 3., 4., 3., 4., 4., 3., 3., 3., 4., 3.,\n",
       "       3., 3., 3., 4., 4., 3., 3., 3., 3., 3., 3., 4., 4., 4., 4., 3., 4.,\n",
       "       3., 4., 4., 2., 3., 4., 3., 3., 4., 2., 3., 3., 3., 2., 4., 3., 3.,\n",
       "       4., 4., 3., 4., 3., 3., 4., 3., 4., 3., 4., 3., 2., 4., 3., 4., 3.,\n",
       "       4., 4., 3., 3., 3., 3., 4., 3., 4., 4., 4., 3., 4., 2., 4., 4., 4.,\n",
       "       4., 3., 4., 3., 4., 4., 4., 3., 3., 4., 4., 3., 2., 3., 3., 4., 4.,\n",
       "       4., 3., 3., 4., 4., 2., 3., 2., 4., 3., 4., 3., 3., 4., 4., 4., 4.,\n",
       "       4., 3., 3., 3., 4., 2., 3., 3., 2., 4., 3., 3., 3., 4., 4., 3., 4.,\n",
       "       4., 4., 3., 4., 3., 3., 3., 4., 3., 3., 4., 4., 4., 3., 4., 3., 4.,\n",
       "       4., 3., 4., 3., 4., 4., 3., 3., 3., 3., 3., 3., 4., 3., 4., 3., 4.,\n",
       "       4., 3., 3., 4., 4., 3., 3., 4., 3., 2., 3., 4., 2., 3., 3., 3., 3.,\n",
       "       3., 4., 3., 4., 2., 3., 4., 4., 4., 3., 4., 3., 4., 4., 4., 4., 3.,\n",
       "       4., 4., 3., 4., 2., 4., 3., 4., 3., 3., 3., 4., 3., 3., 4., 4., 4.,\n",
       "       3., 4., 3., 4., 4., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4.,\n",
       "       4., 4., 3., 3., 3., 4., 3., 3., 3., 4., 4., 3., 3., 3., 4., 3., 3.,\n",
       "       4., 4., 2., 3., 4., 4., 4., 4., 3., 4., 4., 3., 4., 3., 4., 4., 4.,\n",
       "       3., 4., 4., 4., 2., 3., 4., 4., 3., 4., 4., 4., 3., 3., 3., 3., 4.,\n",
       "       4., 4., 4., 4., 3., 4., 3., 4., 3., 4., 4., 4., 3., 4., 4., 3., 4.,\n",
       "       3., 4., 4., 3., 4., 4., 4., 4., 3., 3., 3., 3., 4., 4., 4., 3., 3.,\n",
       "       4., 3., 4., 3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 3., 3., 3., 3.,\n",
       "       3., 4., 4., 3., 3., 2., 3., 4., 3., 3., 3., 4., 4., 3., 2., 4., 3.,\n",
       "       4., 4., 4.])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   4   3   0   0   0]\n",
      " [  0   7  15   1   0   0]\n",
      " [  0   2 129  28   1   0]\n",
      " [  0   0  61  94   1   0]\n",
      " [  0   0   0   7   6   0]\n",
      " [  0   0   0   0   1   0]]\n"
     ]
    }
   ],
   "source": [
    "y_predBLRR = model_blrr.predict(X_testBLRR)\n",
    "y_predBLRR = sc_yblrr.inverse_transform(y_predBLRR).round()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predBLRR)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 3., 3., 4., 4., 3., 3., 4., 3., 4., 4., 3., 3., 3., 4., 3.,\n",
       "       3., 3., 3., 4., 4., 3., 3., 3., 3., 3., 3., 4., 3., 3., 4., 3., 4.,\n",
       "       3., 4., 4., 2., 3., 4., 3., 3., 3., 3., 3., 3., 3., 3., 4., 3., 3.,\n",
       "       4., 4., 3., 3., 2., 3., 4., 3., 4., 3., 5., 3., 2., 4., 3., 3., 3.,\n",
       "       4., 3., 3., 3., 3., 3., 3., 3., 4., 4., 4., 3., 4., 2., 4., 3., 4.,\n",
       "       3., 3., 4., 3., 4., 4., 3., 3., 3., 3., 4., 3., 2., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 4., 4., 3., 3., 3., 4., 3., 4., 3., 3., 4., 4., 4., 4.,\n",
       "       4., 3., 3., 3., 4., 3., 3., 3., 2., 4., 3., 3., 3., 4., 4., 3., 3.,\n",
       "       4., 3., 3., 4., 3., 3., 3., 5., 3., 3., 4., 4., 3., 3., 4., 3., 4.,\n",
       "       4., 3., 4., 3., 4., 4., 3., 3., 3., 3., 3., 3., 4., 3., 4., 4., 4.,\n",
       "       4., 3., 3., 4., 5., 3., 3., 4., 3., 3., 3., 5., 2., 3., 3., 3., 3.,\n",
       "       3., 4., 3., 4., 2., 3., 3., 4., 4., 3., 4., 3., 4., 4., 4., 4., 3.,\n",
       "       4., 4., 3., 4., 2., 4., 3., 4., 3., 3., 3., 4., 3., 3., 4., 4., 4.,\n",
       "       4., 4., 3., 4., 4., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4.,\n",
       "       5., 4., 3., 3., 3., 4., 3., 3., 3., 3., 4., 3., 3., 3., 4., 3., 3.,\n",
       "       4., 4., 2., 3., 4., 3., 4., 4., 3., 4., 4., 3., 4., 3., 3., 3., 4.,\n",
       "       3., 3., 4., 4., 2., 3., 4., 4., 3., 4., 4., 5., 3., 3., 3., 3., 4.,\n",
       "       4., 5., 4., 4., 3., 4., 3., 4., 3., 4., 4., 5., 3., 3., 4., 3., 4.,\n",
       "       3., 4., 4., 3., 3., 4., 3., 3., 3., 3., 3., 3., 4., 4., 3., 3., 3.,\n",
       "       4., 3., 4., 3., 3., 3., 4., 3., 3., 3., 3., 4., 4., 3., 3., 3., 3.,\n",
       "       3., 4., 4., 3., 3., 2., 3., 3., 3., 3., 3., 3., 4., 3., 2., 3., 3.,\n",
       "       4., 4., 4.])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predBLRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 5., 3., 4., 4., 4., 4., 3., 4., 3., 4., 3., 4., 2., 3., 5., 3.,\n",
       "       3., 3., 4., 4., 4., 4., 4., 3., 3., 3., 4., 3., 3., 3., 4., 3., 4.,\n",
       "       1., 3., 4., 1., 2., 4., 3., 3., 4., 2., 3., 3., 3., 1., 4., 4., 4.,\n",
       "       4., 4., 3., 3., 3., 4., 3., 3., 4., 3., 5., 3., 2., 3., 4., 3., 4.,\n",
       "       4., 3., 4., 3., 4., 4., 3., 3., 4., 4., 4., 3., 3., 2., 4., 3., 4.,\n",
       "       3., 3., 4., 3., 4., 4., 4., 3., 4., 3., 4., 3., 1., 3., 3., 4., 4.,\n",
       "       4., 4., 3., 2., 4., 2., 3., 2., 4., 2., 4., 3., 3., 4., 4., 3., 4.,\n",
       "       4., 3., 3., 3., 5., 2., 3., 3., 2., 5., 3., 3., 3., 3., 4., 3., 3.,\n",
       "       4., 4., 3., 3., 3., 3., 3., 5., 3., 4., 4., 4., 3., 3., 4., 2., 4.,\n",
       "       4., 2., 4., 2., 4., 4., 3., 2., 3., 3., 3., 4., 4., 3., 4., 4., 3.,\n",
       "       4., 3., 3., 4., 4., 4., 3., 3., 3., 1., 4., 5., 3., 4., 3., 4., 4.,\n",
       "       3., 4., 4., 3., 1., 3., 4., 3., 4., 4., 4., 4., 4., 4., 3., 4., 4.,\n",
       "       3., 4., 3., 4., 2., 4., 3., 5., 4., 3., 3., 4., 3., 4., 4., 3., 5.,\n",
       "       3., 4., 4., 4., 4., 3., 4., 3., 2., 3., 3., 3., 4., 3., 3., 3., 4.,\n",
       "       6., 4., 3., 3., 3., 4., 3., 3., 3., 4., 4., 3., 3., 3., 4., 2., 4.,\n",
       "       4., 3., 2., 3., 3., 4., 4., 3., 2., 4., 4., 4., 3., 3., 4., 4., 5.,\n",
       "       4., 4., 4., 4., 2., 4., 4., 4., 3., 4., 4., 5., 4., 3., 4., 3., 3.,\n",
       "       4., 5., 4., 4., 3., 4., 2., 4., 3., 4., 3., 5., 4., 4., 3., 3., 4.,\n",
       "       3., 4., 3., 3., 4., 4., 4., 3., 3., 3., 3., 3., 4., 4., 4., 3., 3.,\n",
       "       4., 3., 4., 3., 3., 3., 4., 3., 3., 3., 4., 4., 3., 3., 3., 4., 3.,\n",
       "       3., 3., 4., 3., 4., 2., 3., 4., 3., 3., 4., 3., 3., 3., 1., 3., 3.,\n",
       "       4., 4., 4.])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling the 3 Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>BLRR</th>\n",
       "      <th>NB</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  BLRR   NB  SVM\n",
       "0       3.0   5.0  4.0  4.0\n",
       "1       5.0   4.0  6.0  4.0\n",
       "2       3.0   3.0  3.0  3.0\n",
       "3       4.0   3.0  3.0  3.0\n",
       "4       4.0   4.0  5.0  4.0\n",
       "5       4.0   4.0  3.0  3.0\n",
       "6       4.0   3.0  3.0  4.0\n",
       "7       3.0   3.0  4.0  3.0\n",
       "8       4.0   4.0  4.0  4.0\n",
       "9       3.0   3.0  3.0  3.0\n",
       "10      4.0   4.0  5.0  4.0\n",
       "11      3.0   4.0  4.0  4.0\n",
       "12      4.0   3.0  4.0  3.0\n",
       "13      2.0   3.0  3.0  3.0\n",
       "14      3.0   3.0  3.0  3.0\n",
       "15      5.0   4.0  5.0  4.0\n",
       "16      3.0   3.0  3.0  3.0\n",
       "17      3.0   3.0  3.0  3.0\n",
       "18      3.0   3.0  3.0  3.0\n",
       "19      4.0   3.0  3.0  3.0\n",
       "20      4.0   4.0  5.0  4.0\n",
       "21      4.0   4.0  4.0  4.0\n",
       "22      4.0   3.0  4.0  3.0\n",
       "23      4.0   3.0  3.0  3.0\n",
       "24      3.0   3.0  3.0  3.0\n",
       "25      3.0   3.0  3.0  3.0\n",
       "26      3.0   3.0  3.0  3.0\n",
       "27      4.0   3.0  3.0  3.0\n",
       "28      3.0   4.0  4.0  4.0\n",
       "29      3.0   3.0  4.0  4.0\n",
       "..      ...   ...  ...  ...\n",
       "330     3.0   3.0  3.0  3.0\n",
       "331     3.0   3.0  3.0  3.0\n",
       "332     3.0   3.0  3.0  3.0\n",
       "333     4.0   3.0  4.0  4.0\n",
       "334     4.0   4.0  4.0  4.0\n",
       "335     3.0   4.0  3.0  4.0\n",
       "336     3.0   3.0  3.0  3.0\n",
       "337     3.0   3.0  2.0  3.0\n",
       "338     4.0   3.0  2.0  3.0\n",
       "339     3.0   3.0  4.0  3.0\n",
       "340     3.0   3.0  3.0  3.0\n",
       "341     3.0   4.0  4.0  4.0\n",
       "342     4.0   4.0  4.0  4.0\n",
       "343     3.0   3.0  2.0  3.0\n",
       "344     4.0   3.0  3.0  3.0\n",
       "345     2.0   2.0  2.0  2.0\n",
       "346     3.0   3.0  3.0  3.0\n",
       "347     4.0   3.0  3.0  4.0\n",
       "348     3.0   3.0  2.0  3.0\n",
       "349     3.0   3.0  3.0  3.0\n",
       "350     4.0   3.0  3.0  3.0\n",
       "351     3.0   3.0  4.0  4.0\n",
       "352     3.0   4.0  4.0  4.0\n",
       "353     3.0   3.0  3.0  3.0\n",
       "354     1.0   2.0  3.0  2.0\n",
       "355     3.0   3.0  4.0  4.0\n",
       "356     3.0   3.0  3.0  3.0\n",
       "357     4.0   4.0  3.0  4.0\n",
       "358     4.0   4.0  4.0  4.0\n",
       "359     4.0   4.0  4.0  4.0\n",
       "\n",
       "[360 rows x 4 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = pd.Series(y_test.ravel())\n",
    "predNB = pd.Series(y_predNB)\n",
    "predSVM = pd.Series(y_predSVM)\n",
    "predBLRR = pd.Series(y_predBLRR)\n",
    "\n",
    "data = {\"Actual\": actual,\n",
    "        \"NB\": predNB, \n",
    "        \"SVM\": predSVM, \n",
    "        \"BLRR\": predBLRR} \n",
    "results = pd.concat(data, axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>BLRR</th>\n",
       "      <th>NB</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  BLRR   NB  SVM  Ensemble\n",
       "0       3.0   5.0  4.0  4.0       4.0\n",
       "1       5.0   4.0  6.0  4.0       4.0\n",
       "2       3.0   3.0  3.0  3.0       3.0\n",
       "3       4.0   3.0  3.0  3.0       3.0\n",
       "4       4.0   4.0  5.0  4.0       4.0\n",
       "5       4.0   4.0  3.0  3.0       3.0\n",
       "6       4.0   3.0  3.0  4.0       3.0\n",
       "7       3.0   3.0  4.0  3.0       3.0\n",
       "8       4.0   4.0  4.0  4.0       4.0\n",
       "9       3.0   3.0  3.0  3.0       3.0\n",
       "10      4.0   4.0  5.0  4.0       4.0\n",
       "11      3.0   4.0  4.0  4.0       4.0\n",
       "12      4.0   3.0  4.0  3.0       3.0\n",
       "13      2.0   3.0  3.0  3.0       3.0\n",
       "14      3.0   3.0  3.0  3.0       3.0\n",
       "15      5.0   4.0  5.0  4.0       4.0\n",
       "16      3.0   3.0  3.0  3.0       3.0\n",
       "17      3.0   3.0  3.0  3.0       3.0\n",
       "18      3.0   3.0  3.0  3.0       3.0\n",
       "19      4.0   3.0  3.0  3.0       3.0\n",
       "20      4.0   4.0  5.0  4.0       4.0\n",
       "21      4.0   4.0  4.0  4.0       4.0\n",
       "22      4.0   3.0  4.0  3.0       3.0\n",
       "23      4.0   3.0  3.0  3.0       3.0\n",
       "24      3.0   3.0  3.0  3.0       3.0\n",
       "25      3.0   3.0  3.0  3.0       3.0\n",
       "26      3.0   3.0  3.0  3.0       3.0\n",
       "27      4.0   3.0  3.0  3.0       3.0\n",
       "28      3.0   4.0  4.0  4.0       4.0\n",
       "29      3.0   3.0  4.0  4.0       4.0\n",
       "..      ...   ...  ...  ...       ...\n",
       "330     3.0   3.0  3.0  3.0       3.0\n",
       "331     3.0   3.0  3.0  3.0       3.0\n",
       "332     3.0   3.0  3.0  3.0       3.0\n",
       "333     4.0   3.0  4.0  4.0       4.0\n",
       "334     4.0   4.0  4.0  4.0       4.0\n",
       "335     3.0   4.0  3.0  4.0       4.0\n",
       "336     3.0   3.0  3.0  3.0       3.0\n",
       "337     3.0   3.0  2.0  3.0       3.0\n",
       "338     4.0   3.0  2.0  3.0       3.0\n",
       "339     3.0   3.0  4.0  3.0       3.0\n",
       "340     3.0   3.0  3.0  3.0       3.0\n",
       "341     3.0   4.0  4.0  4.0       4.0\n",
       "342     4.0   4.0  4.0  4.0       4.0\n",
       "343     3.0   3.0  2.0  3.0       3.0\n",
       "344     4.0   3.0  3.0  3.0       3.0\n",
       "345     2.0   2.0  2.0  2.0       2.0\n",
       "346     3.0   3.0  3.0  3.0       3.0\n",
       "347     4.0   3.0  3.0  4.0       3.0\n",
       "348     3.0   3.0  2.0  3.0       3.0\n",
       "349     3.0   3.0  3.0  3.0       3.0\n",
       "350     4.0   3.0  3.0  3.0       3.0\n",
       "351     3.0   3.0  4.0  4.0       4.0\n",
       "352     3.0   4.0  4.0  4.0       4.0\n",
       "353     3.0   3.0  3.0  3.0       3.0\n",
       "354     1.0   2.0  3.0  2.0       2.0\n",
       "355     3.0   3.0  4.0  4.0       4.0\n",
       "356     3.0   3.0  3.0  3.0       3.0\n",
       "357     4.0   4.0  3.0  4.0       4.0\n",
       "358     4.0   4.0  4.0  4.0       4.0\n",
       "359     4.0   4.0  4.0  4.0       4.0\n",
       "\n",
       "[360 rows x 5 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Ensemble'] = np.where(\n",
    "                            (results['NB'] == results['BLRR']) |\n",
    "                            (results['NB'] == results['SVM']),\n",
    "                            results['NB'],\n",
    "                            results['BLRR']\n",
    "                        )\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using QWK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QWK scores for NB, SVR and BLRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Dong et al. (SUTD), averaged QWK over all 8 prompts\n",
    "\n",
    "Model BLRR SVR\n",
    "\n",
    "Avg 0.725 0.682"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.29      0.36         7\n",
      "         2.0       0.44      0.52      0.48        23\n",
      "         3.0       0.66      0.68      0.67       160\n",
      "         4.0       0.68      0.60      0.64       156\n",
      "         5.0       0.39      0.69      0.50        13\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       360\n",
      "   macro avg       0.45      0.46      0.44       360\n",
      "weighted avg       0.64      0.62      0.63       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpt = classification_report(y_test, y_predNB)\n",
    "print(rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6364890158605063\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(y_test, y_predNB, weights=\"quadratic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "         2.0       0.61      0.48      0.54        23\n",
      "         3.0       0.67      0.73      0.70       160\n",
      "         4.0       0.66      0.71      0.69       156\n",
      "         5.0       0.00      0.00      0.00        13\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       360\n",
      "   macro avg       0.32      0.32      0.32       360\n",
      "weighted avg       0.62      0.66      0.64       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "rpt = classification_report(y_test, y_predSVM)\n",
    "print(rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6068548387096774\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(y_test, y_predSVM, weights=\"quadratic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "         2.0       0.54      0.30      0.39        23\n",
      "         3.0       0.62      0.81      0.70       160\n",
      "         4.0       0.72      0.60      0.66       156\n",
      "         5.0       0.67      0.46      0.55        13\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       360\n",
      "   macro avg       0.42      0.36      0.38       360\n",
      "weighted avg       0.65      0.66      0.64       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpt = classification_report(y_test, y_predBLRR)\n",
    "print(rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5863095238095238\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(y_test, y_predBLRR, weights=\"quadratic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         7\n",
      "         2.0       0.58      0.48      0.52        23\n",
      "         3.0       0.66      0.75      0.70       160\n",
      "         4.0       0.69      0.69      0.69       156\n",
      "         5.0       0.83      0.38      0.53        13\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       360\n",
      "   macro avg       0.46      0.38      0.41       360\n",
      "weighted avg       0.66      0.68      0.66       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rpt = classification_report(y_test,results['Ensemble'])\n",
    "print(rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6425803951956606\n"
     ]
    }
   ],
   "source": [
    "print(cohen_kappa_score(y_test, results['Ensemble'], weights=\"quadratic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to execute the notebook is 242.39521551132202\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"Total time to execute the notebook is \" + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QWK scores output are from -1 to 1, where -1 means that it is totally wrong while 1 is a perfect match (classification).  The aim is to get as close as possible to 1, with a score of 0.6 being generally accepted as a good score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the output of the QWK agreements, the score is just \"moderate agreement\".  Work now is to achieve substantial agreement.\n",
    "\n",
    "https://www.statisticshowto.com/cohens-kappa-statistic/\n",
    "\n",
    "In short, BLRR works better than SVM but a small margin but better than NB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QWK Scores (Manual Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(cm) # Just to get the same size as the confusion matrix from above\n",
    "w = np.zeros((N,N)) # create a matrix of N by N\n",
    "d = (N-1)**2 # the weighted portion\n",
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        w[i][j] = float(((i-j)**2)/d) \n",
    "w # The weighted matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_predNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_hist=np.zeros([N])\n",
    "for item in y_test: \n",
    "    act_hist[item-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hist=np.zeros([N])\n",
    "for item in y_predNB: \n",
    "    pred_hist[item-1]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.outer(act_hist, pred_hist)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = E/E.sum()\n",
    "E.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = cm/cm.sum()\n",
    "cm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=0\n",
    "den=0\n",
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        num+=w[i][j]*cm[i][j]\n",
    "        den+=w[i][j]*E[i][j]\n",
    "            \n",
    "weighted_kappa = (1 - (num/den))\n",
    "weighted_kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
